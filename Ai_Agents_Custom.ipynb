{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan-Az/Ai-Agents/blob/main/Ai_Agents_Custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz3vXCgbryJg"
      },
      "source": [
        "# Building a simple custom Ai Agent pipeline.\n",
        "In this notebook, I will create a simple agent that utilizes predefined tools to answer a question. The actual architecture is a pre-trained LLM to process the text query input. The LLM is given a prompt and pre-defined tool/functions to use when answering the question.\n",
        "\n",
        "For this assignment, I will have the LLM (ChatGPT - token needed) answer questions using a function that queries information from an online source."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265zpED-t32u"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JowJegiMtsOc",
        "outputId": "bc580071-f252-4a48-c29a-e11cb1b11e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n"
          ]
        }
      ],
      "source": [
        "! pip install openai==1.14.2\n",
        "import openai\n",
        "import re\n",
        "import httpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pmfR1CsigSb-",
        "outputId": "be836bd7-4b5a-4cb8-d49c-9145b6d4e9b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.2'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ4pMQnWxw2Q"
      },
      "source": [
        "## Chain-Of-Thought Prompting\n",
        "\n",
        "When creating my prompt, I decided to prepend the examples of how to utilize the tools with a general thought process using the Chain-of-Thought theory:\n",
        "\n",
        "\"You answer questions based on a chain of \"Thought, Action, Pause, Observation\",\n",
        "followed by a second \"Thought, Pause, Observation\" chain of thought.\n",
        "At the end of the second chain of thought you output an 'Answer'.\"\n",
        "Use Thought to describe your thought process about the question you were asked.\n",
        "Use Action to use one of the 'Action' tools available to you - then return Pause.\n",
        "Observation will be a summary of the Thought & Action.\"\n",
        "\n",
        "I believe this is an important addition to add as it helps structure the answer returned by the large language model. This method of structuring a prompt is also known as a CoT (Chain of Thought), which helps improve the performance by allowing the model to re-iterate its' answer\n",
        " based on its previous 'thoughts'.\n",
        "\n",
        " Since the model is asked to only call the 'Action' step of its' chain once, it may only observe a single set of data and craft a single response 'Answer'. This is also known as the chain-of-thought.\n",
        "\n",
        " Tree-of-Thought is a more advanced version that will have the model make multiple actions and re-contextualize it's answer based on new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eEojLTWvuNEY"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "You answer questions based on a chain of \"Thought, Action, Pause, Observation\",\n",
        "followed by a second \"Thought, Pause, Observation\" chain of thought.\n",
        "At the end of the second chain of thought you output an 'Answer'.\"\n",
        "Use Thought to describe your thought process about the question you were asked.\n",
        "Use Action to use one of the 'Action' tools available to you - then return Pause.\n",
        "Observation will be a summary of the Thought & Action.\n",
        "Your available actions are:\n",
        "wikipedia:\n",
        "e.g. Wikipedia: Nasa Projects\n",
        "Returns a summary from searching Wikipedia.\n",
        "calculate:\n",
        "e.g. calculate: 9 + 12\n",
        "Runs a calculation and returns the result.\n",
        "Example Session:\n",
        "Question: How does nasa analyse images?\n",
        "Chain of Thought 1:\n",
        "Thought: I should look up nasa image analysis on Wikipedia.\n",
        "Action: wikipedia: Image Analysis is a technique in Data Science.\n",
        "Pause\n",
        "Observation: I found that image analysis is a technique in Data Science.\n",
        "Chain of Thought 2:\n",
        "Thought 2: I should look up image analysis and nasa on Wikipedia.\n",
        "Pause\n",
        "Observation 2: NASA has acquired samples from Mars, they analyzed multiple images and created a mosaic.\n",
        "Answer: NASA has acquired samples from Mars. They seem to have used a technique where mosaic images are scanned, which is a technique also used in Data analysis for processing large amounts of data in parallel.\n",
        "\"\"\".strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8jlnPzEy3XN"
      },
      "source": [
        "## The Chat Bot Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-wA2AWmSuZLO"
      },
      "outputs": [],
      "source": [
        "action_re = re.compile('^Action: (\\w+): (.*)$')\n",
        "def query(question, max_turns=1):\n",
        "    i = 0\n",
        "    bot = ChatBot(prompt)\n",
        "    next_prompt = question\n",
        "    result = bot(next_prompt)\n",
        "    print(result)\n",
        "    # This section can be reimplemented for Tree-Of-Thought\n",
        "    #while i < max_turns:\n",
        "    #    i += 1\n",
        "    #    result = bot(next_prompt)\n",
        "    #    print(result)\n",
        "    #    actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
        "    #    if actions:\n",
        "    #        # There is an action to run\n",
        "    #        action, action_input = actions[0].groups()\n",
        "    #        if action not in known_actions:\n",
        "    #            raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
        "    #        print(\" -- running {} {}\".format(action, action_input))\n",
        "    #        observation = known_actions[action](action_input)\n",
        "    #        print(\"Observation:\", observation)\n",
        "    #        next_prompt = \"Observation: {}\".format(observation)\n",
        "    #    else:\n",
        "    #        return\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I0G4EySxqQt3"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"sk-...\"\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self, system=\"\"):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.execute()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "    def execute(self):\n",
        "        completion = openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=self.messages)\n",
        "        # Uncomment this to print out token usage each time, e.g.\n",
        "        # {\"completion_tokens\": 86, \"prompt_tokens\": 26, \"total_tokens\": 112}\n",
        "        print(completion.usage)\n",
        "        return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v3l9KHvhunTv"
      },
      "outputs": [],
      "source": [
        "def wikipedia(q):\n",
        "    return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
        "        \"action\": \"query\",\n",
        "        \"list\": \"search\",\n",
        "        \"srsearch\": q,\n",
        "        \"format\": \"json\"\n",
        "    }).json()[\"query\"][\"search\"][0][\"snippet\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bI88E1Uouvd2"
      },
      "outputs": [],
      "source": [
        "def calculate(what):\n",
        "    return eval(what)\n",
        "\n",
        "known_actions = {\n",
        "    \"wikipedia\": wikipedia,\n",
        "    \"calculate\": calculate\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmnTrsB0vbdM",
        "outputId": "f8ccd4a4-fc4b-448c-a6ec-42f0f65a975e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CompletionUsage(completion_tokens=170, prompt_tokens=317, total_tokens=487)\n",
            "Chain of Thought 1:\n",
            "Thought: I could search for movie and TV show streaming applications that support watching with multiple people simultaneously.\n",
            "Action: wikipedia: Watch Party Streaming Apps\n",
            "Pause\n",
            "Observation: There are several streaming applications that offer the capability to watch movies and TV shows with multiple people at the same time, such as Netflix Party and Amazon Prime Video Watch Party.\n",
            "\n",
            "Chain of Thought 2:\n",
            "Thought 2: I should look up more details about Netflix Party and Amazon Prime Video Watch Party.\n",
            "Pause\n",
            "Observation 2: Both Netflix Party and Amazon Prime Video Watch Party allow users to synchronize playback and communicate through text chat while watching content together.\n",
            "\n",
            "Answer: Yes, there are movie and TV show streaming applications like Netflix Party and Amazon Prime Video Watch Party that enable users to watch with multiple people at the same time and interact through text chat.\n"
          ]
        }
      ],
      "source": [
        "query(\"Are there movie and tv show streaming applications that allow you to watch with multiple people at the same time?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BgdHlOovv7ce",
        "outputId": "bc98e346-913e-46c2-9c3f-ec25d3774687"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.2'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkR0Rz75fnQ4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPqFDMIKB3axXX2QHYRwaDi",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
