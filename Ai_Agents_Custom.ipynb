{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnvtyt+KJJPTSJxI3Xx19q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan-Az/Ai-Agents/blob/main/Ai_Agents_Custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a simple custom Ai Agent pipeline.\n",
        "In this notebook, I will create a simple agent that utilizes predefined tools to answer a question. The actual architecture is a pre-trained LLM to process the text query input. The LLM is given a prompt and pre-defined tool/functions to use when answering the question.\n",
        "\n",
        "For this assignment, I will have the LLM (ChatGPT - token needed) answer questions using a function that queries information from an online source."
      ],
      "metadata": {
        "id": "Rz3vXCgbryJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "265zpED-t32u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai\n",
        "import openai\n",
        "import re\n",
        "import httpx"
      ],
      "metadata": {
        "id": "JowJegiMtsOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-Of-Thought Prompting\n",
        "\n",
        "When creating my prompt, I decided to prepend the examples of how to utilize the tools with a general thought process using the Chain-of-Thought theory:\n",
        "\n",
        "\"You answer questions based on a chain of \"Thought, Action, Pause, Observation\",\n",
        "followed by a second \"Thought, Pause, Observation\" chain of thought.\n",
        "At the end of the second chain of thought you output an 'Answer'.\"\n",
        "Use Thought to describe your thought process about the question you were asked.\n",
        "Use Action to use one of the 'Action' tools available to you - then return Pause.\n",
        "Observation will be a summary of the Thought & Action.\"\n",
        "\n",
        "I believe this is an important addition to add as it helps structure the answer returned by the large language model. This method of structuring a prompt is also known as a CoT (Chain of Thought), which helps improve the performance by allowing the model to re-iterate its' answer\n",
        " based on its previous 'thoughts'.\n",
        "\n",
        " Since the model is asked to only call the 'Action' step of its' chain once, it may only observe a single set of data and craft a single response 'Answer'. This is also known as the chain-of-thought.\n",
        "\n",
        " Tree-of-Thought is a more advanced version that will have the model make multiple actions and re-contextualize it's answer based on new data."
      ],
      "metadata": {
        "id": "TQ4pMQnWxw2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You answer questions based on a chain of \"Thought, Action, Pause, Observation\",\n",
        "followed by a second \"Thought, Pause, Observation\" chain of thought.\n",
        "At the end of the second chain of thought you output an 'Answer'.\"\n",
        "Use Thought to describe your thought process about the question you were asked.\n",
        "Use Action to use one of the 'Action' tools available to you - then return Pause.\n",
        "Observation will be a summary of the Thought & Action.\n",
        "Your available actions are:\n",
        "wikipedia:\n",
        "e.g. Wikipedia: Nasa Projects\n",
        "Returns a summary from searching Wikipedia.\n",
        "calculate:\n",
        "e.g. calculate: 9 + 12\n",
        "Runs a calculation and returns the result.\n",
        "Example Session:\n",
        "Question: How does nasa analyse images?\n",
        "Chain of Thought 1:\n",
        "Thought: I should look up nasa image analysis on Wikipedia.\n",
        "Action: wikipedia: Image Analysis is a technique in Data Science.\n",
        "Pause\n",
        "Observation: I found that image analysis is a technique in Data Science.\n",
        "Chain of Thought 2:\n",
        "Thought 2: I should look up image analysis and nasa on Wikipedia.\n",
        "Pause\n",
        "Observation 2: NASA has acquired samples from Mars, they analyzed multiple images and created a mosaic.\n",
        "Answer: NASA has acquired samples from Mars. They seem to have used a technique where mosaic images are scanned, which is a technique also used in Data analysis for processing large amounts of data in parallel.\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "eEojLTWvuNEY"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Chat Bot Agent"
      ],
      "metadata": {
        "id": "u8jlnPzEy3XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_re = re.compile('^Action: (\\w+): (.*)$')\n",
        "def query(question, max_turns=1):\n",
        "    i = 0\n",
        "    bot = ChatBot(prompt)\n",
        "    next_prompt = question\n",
        "    result = bot(next_prompt)\n",
        "    print(result)\n",
        "    # This section can be reimplemented for Tree-Of-Thought\n",
        "    #while i < max_turns:\n",
        "    #    i += 1\n",
        "    #    result = bot(next_prompt)\n",
        "    #    print(result)\n",
        "    #    actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
        "    #    if actions:\n",
        "    #        # There is an action to run\n",
        "    #        action, action_input = actions[0].groups()\n",
        "    #        if action not in known_actions:\n",
        "    #            raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
        "    #        print(\" -- running {} {}\".format(action, action_input))\n",
        "    #        observation = known_actions[action](action_input)\n",
        "    #        print(\"Observation:\", observation)\n",
        "    #        next_prompt = \"Observation: {}\".format(observation)\n",
        "    #    else:\n",
        "    #        return\n",
        "    return"
      ],
      "metadata": {
        "id": "-wA2AWmSuZLO"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "I0G4EySxqQt3"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"sk-...\"\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self, system=\"\"):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.execute()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "    def execute(self):\n",
        "        completion = openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=self.messages)\n",
        "        # Uncomment this to print out token usage each time, e.g.\n",
        "        # {\"completion_tokens\": 86, \"prompt_tokens\": 26, \"total_tokens\": 112}\n",
        "        print(completion.usage)\n",
        "        return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wikipedia(q):\n",
        "    return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
        "        \"action\": \"query\",\n",
        "        \"list\": \"search\",\n",
        "        \"srsearch\": q,\n",
        "        \"format\": \"json\"\n",
        "    }).json()[\"query\"][\"search\"][0][\"snippet\"]"
      ],
      "metadata": {
        "id": "v3l9KHvhunTv"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(what):\n",
        "    return eval(what)\n",
        "\n",
        "known_actions = {\n",
        "    \"wikipedia\": wikipedia,\n",
        "    \"calculate\": calculate\n",
        "}"
      ],
      "metadata": {
        "id": "bI88E1Uouvd2"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query(\"Are there movie and tv show streaming applications that allow you to watch with multiple people at the same time?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmnTrsB0vbdM",
        "outputId": "7987b76e-8e66-46ec-c68b-e19b8d347551"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CompletionUsage(completion_tokens=160, prompt_tokens=317, total_tokens=477)\n",
            "Chain of Thought 1:\n",
            "Thought: I should search for movie and tv show streaming applications that support watching with multiple people simultaneously.\n",
            "Action: wikipedia: List of streaming services\n",
            "Pause\n",
            "Observation: The list of streaming services may include platforms that offer group viewing features.\n",
            "\n",
            "Chain of Thought 2:\n",
            "Thought 2: I should look up the specific features of popular streaming services to see if they support watching with multiple people at the same time.\n",
            "Pause\n",
            "Observation 2: Some streaming services like Netflix and Disney+ offer a \"Watch Party\" feature that allows users to watch together from different locations.\n",
            "Answer: Yes, there are movie and tv show streaming applications like Netflix and Disney+ that have features allowing users to watch with multiple people at the same time through their \"Watch Party\" feature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BgdHlOovv7ce"
      },
      "execution_count": 111,
      "outputs": []
    }
  ]
}